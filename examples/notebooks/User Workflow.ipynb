{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0d19096",
   "metadata": {},
   "source": [
    "First we fetch the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b52fb9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data fetched\n",
      "Saving to files\n"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X, y = shap.datasets.adult()\n",
    "print(\"Data fetched\")\n",
    "target_feature = \"income\"\n",
    "y = [1 if y_i else 0 for y_i in y]\n",
    "\n",
    "full_data = X.copy()\n",
    "full_data[target_feature] = y\n",
    "\n",
    "data_train, data_test = train_test_split(\n",
    "    full_data, test_size=4000, random_state=96132, stratify=full_data[target_feature]\n",
    ")\n",
    "\n",
    "# Don't write out the row indices to the CSV.....\n",
    "print(\"Saving to files\")\n",
    "data_train.to_parquet(\"adult_train.parquet\", index=False)\n",
    "data_test.to_parquet(\"adult_test.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992be15f",
   "metadata": {},
   "source": [
    "Now create an MLClient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14f8577b",
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_id = '589c7ae9-223e-45e3-a191-98433e0821a9'\n",
    "resource_group = 'amlisdkv2-rg-1638957740'\n",
    "workspace_name = 'amlisdkv21638957740'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efe49cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "ml_client = MLClient(credential=DefaultAzureCredential(exclude_shared_token_cache_credential=True),\n",
    "                     subscription_id=subscription_id,\n",
    "                     resource_group_name=resource_group,\n",
    "                     workspace_name=workspace_name,\n",
    "                     logging_enable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af9924f",
   "metadata": {},
   "source": [
    "Upload the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb43cfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ml.entities import Data\n",
    "\n",
    "train_dataset = Data(\n",
    "    name=\"Adult_Train_from_Notebook\",\n",
    "    local_path=\"adult_train.parquet\",\n",
    "    version=\"1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ae13088",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading adult_train.parquet: 100%|█████████████████████████████████████████████████| 158k/158k [00:00<00:00, 925kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data({'is_anonymous': False, 'auto_increment_version': False, 'name': 'Adult_Train_from_Notebook', 'description': None, 'tags': {}, 'properties': {}, 'id': '/subscriptions/589c7ae9-223e-45e3-a191-98433e0821a9/resourceGroups/amlisdkv2-rg-1638957740/providers/Microsoft.MachineLearningServices/workspaces/amlisdkv21638957740/data/Adult_Train_from_Notebook/versions/1', 'base_path': './', 'creation_context': <azure.ml._restclient.v2021_03_01_preview.models._models_py3.SystemData object at 0x000001C99C78C2E0>, 'serialize': <msrest.serialization.Serializer object at 0x000001C99C784FA0>, 'version': '1', 'local_path': None, 'path': 'LocalUpload/3c08dc2a27945f6adbd2ef2dfe7ab079/adult_train.parquet', 'datastore': '/subscriptions/589c7ae9-223e-45e3-a191-98433e0821a9/resourceGroups/amlisdkv2-rg-1638957740/providers/Microsoft.MachineLearningServices/workspaces/amlisdkv21638957740/datastores/workspaceblobstore'})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.data.create_or_update(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "552abe1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading adult_test.parquet: 100%|████████████████████████████████████████████████| 31.6k/31.6k [00:00<00:00, 430kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data({'is_anonymous': False, 'auto_increment_version': False, 'name': 'Adult_Test_from_Notebook', 'description': None, 'tags': {}, 'properties': {}, 'id': '/subscriptions/589c7ae9-223e-45e3-a191-98433e0821a9/resourceGroups/amlisdkv2-rg-1638957740/providers/Microsoft.MachineLearningServices/workspaces/amlisdkv21638957740/data/Adult_Test_from_Notebook/versions/1', 'base_path': './', 'creation_context': <azure.ml._restclient.v2021_03_01_preview.models._models_py3.SystemData object at 0x000001C99C76EAC0>, 'serialize': <msrest.serialization.Serializer object at 0x000001C99C76E9D0>, 'version': '1', 'local_path': None, 'path': 'LocalUpload/0f2894e892201167f37ded36e2d2d0b2/adult_test.parquet', 'datastore': '/subscriptions/589c7ae9-223e-45e3-a191-98433e0821a9/resourceGroups/amlisdkv2-rg-1638957740/providers/Microsoft.MachineLearningServices/workspaces/amlisdkv21638957740/datastores/workspaceblobstore'})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = Data(\n",
    "    name=\"Adult_Test_from_Notebook\",\n",
    "    local_path=\"adult_test.parquet\",\n",
    "    version=\"1\"\n",
    ")\n",
    "ml_client.data.create_or_update(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc9533d",
   "metadata": {},
   "source": [
    "# Creating the Model\n",
    "\n",
    "To simplify the model creation process, we're going to use a pipeline.\n",
    "\n",
    "Before we do anything else, we need to specify the version of the RAI components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "133c10c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "version_string = '1638957740'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f30de0d",
   "metadata": {},
   "source": [
    "Now we can create the training script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6aaac6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting training_script.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile training_script.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "\n",
    "from azureml.core import Run\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def parse_args():\n",
    "    # setup arg parser\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # add arguments\n",
    "    parser.add_argument(\"--training_data\", type=str, help=\"Path to training data\")\n",
    "    parser.add_argument(\"--target_column_name\", type=str, help=\"Name of target column\")\n",
    "    parser.add_argument(\"--model_output\", type=str, help=\"Path of output model\")\n",
    "\n",
    "    # parse args\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # return args\n",
    "    return args\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    current_experiment = Run.get_context().experiment\n",
    "    tracking_uri = current_experiment.workspace.get_mlflow_tracking_uri()\n",
    "    print(\"tracking_uri: {0}\".format(tracking_uri))\n",
    "    mlflow.set_tracking_uri(tracking_uri)\n",
    "    mlflow.set_experiment(current_experiment.name)\n",
    "\n",
    "    # Read in data\n",
    "    print(\"Reading data\")\n",
    "    all_data = pd.read_parquet(args.training_data)\n",
    "\n",
    "    print(\"Extracting X_train, y_train\")\n",
    "    print(\"all_data cols: {0}\".format(all_data.columns))\n",
    "    y_train = all_data[args.target_column_name]\n",
    "    X_train = all_data.drop(labels=args.target_column_name, axis=\"columns\")\n",
    "    print(\"X_train cols: {0}\".format(X_train.columns))\n",
    "\n",
    "    print(\"Training model\")\n",
    "    model = LogisticRegression(solver=\"liblinear\")\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # print(\"Registering via MLFlow\")\n",
    "    # mlflow.sklearn.log_model(sk_model=model, registered_model_name=\"lr_classifier_mlflow\", artifact_path=\"some_path\")\n",
    "\n",
    "    # Saving model with mlflow\n",
    "    with tempfile.TemporaryDirectory() as td:\n",
    "        print(\"Saving model with MLFlow to temporary directory\")\n",
    "        tmp_output_dir = os.path.join(td, \"my_model_dir\")\n",
    "        mlflow.sklearn.save_model(sk_model=model, path=tmp_output_dir)\n",
    "\n",
    "        print(\"Copying MLFlow model to output path\")\n",
    "        for file_name in os.listdir(tmp_output_dir):\n",
    "            print(\"  Copying: \", file_name)\n",
    "            # As of Python 3.8, copytree will acquire dirs_exist_ok as\n",
    "            # an option, removing the need for listdir\n",
    "            shutil.copy2(src=os.path.join(tmp_output_dir, file_name), dst=os.path.join(args.model_output, file_name))\n",
    "\n",
    "\n",
    "# run script\n",
    "if __name__ == \"__main__\":\n",
    "    # add space in logs\n",
    "    print(\"*\" * 60)\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "    # parse args\n",
    "    args = parse_args()\n",
    "\n",
    "    # run main function\n",
    "    main(args)\n",
    "\n",
    "    # add space in logs\n",
    "    print(\"*\" * 60)\n",
    "    print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82717217",
   "metadata": {},
   "source": [
    "Now, we want to place this into a component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e852f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommandComponent({'auto_increment_version': False, 'is_anonymous': False, 'name': 'MyTrainingComponent', 'description': None, 'tags': {}, 'properties': {}, 'id': '/subscriptions/589c7ae9-223e-45e3-a191-98433e0821a9/resourceGroups/amlisdkv2-rg-1638957740/providers/Microsoft.MachineLearningServices/workspaces/amlisdkv21638957740/components/MyTrainingComponent/versions/1', 'base_path': None, 'creation_context': <azure.ml._restclient.v2021_10_01.models._models_py3.SystemData object at 0x000001C99CA2BB50>, 'serialize': <msrest.serialization.Serializer object at 0x000001C99CA38850>, 'command': 'python training_script.py --training_data ${{inputs.training_data}} --target_column_name ${{inputs.target_column_name}} --model_output ${{outputs.model_output}}', 'code': '/subscriptions/589c7ae9-223e-45e3-a191-98433e0821a9/resourceGroups/amlisdkv2-rg-1638957740/providers/Microsoft.MachineLearningServices/workspaces/amlisdkv21638957740/codes/8702f8b6-d966-4546-a9dd-db4133259936/versions/1', 'environment_variables': {}, 'environment': '/subscriptions/589c7ae9-223e-45e3-a191-98433e0821a9/resourceGroups/amlisdkv2-rg-1638957740/providers/Microsoft.MachineLearningServices/workspaces/amlisdkv21638957740/environments/AML-RAI-Environment/versions/1638957740', 'distribution': None, 'resources': OrderedDict([('instance_count', 1)]), 'version': '1', 'schema': 'https://azuremlschemas.azureedge.net/stable/commandComponent.schema.json', 'type': 'command', 'display_name': 'Simple training component', 'is_deterministic': True, 'inputs': {'training_data': {'name': 'training_data', 'optional': 'False', 'type': 'path'}, 'target_column_name': {'name': 'target_column_name', 'optional': 'False', 'type': 'string'}}, 'outputs': {'model_output': {'name': 'model_output', 'type': 'path'}}, 'yaml_str': None, 'other_parameter': {}})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ml.entities import Code, CommandComponent\n",
    "\n",
    "training_code = Code(\n",
    "    local_path='training_script.py'\n",
    ")\n",
    "\n",
    "training_inputs = {\n",
    "    'training_data': { 'type': 'path'},\n",
    "    'target_column_name': { 'type': 'string'}\n",
    "}\n",
    "\n",
    "training_outputs = {\n",
    "    'model_output': { 'type': 'path'}\n",
    "}\n",
    "\n",
    "training_component = CommandComponent(\n",
    "    name=\"MyTrainingComponent\",\n",
    "    version=\"1\",\n",
    "    display_name=\"Simple training component\",\n",
    "    code=training_code,\n",
    "    environment=f\"AML-RAI-Environment:{version_string}\",\n",
    "    inputs=training_inputs,\n",
    "    outputs=training_outputs,\n",
    "    command=\"python training_script.py \" \\\n",
    "            \"--training_data ${{inputs.training_data}} \" \\\n",
    "            \"--target_column_name ${{inputs.target_column_name}} \" \\\n",
    "            \"--model_output ${{outputs.model_output}}\"\n",
    ")\n",
    "\n",
    "ml_client.components.create_or_update(training_component)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f6521b",
   "metadata": {},
   "source": [
    "## Running a training pipeline\n",
    "\n",
    "Now we have a script which can train a model, we need to run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "984e899d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from azure.ml.entities import JobInput, ComponentJob, PipelineJob\n",
    "\n",
    "model_name_suffix = int(time.time())\n",
    "model_name = 'my_trained_nb_model'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575684a8",
   "metadata": {},
   "source": [
    "This is going to be a two component pipeline. The first will be the one we created above, which will train our model. The second will register it in AzureML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b400dcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The overall inputs for the pipeline\n",
    "\n",
    "pipeline_inputs = {\n",
    "    'target_column_name': 'income',\n",
    "    'my_training_data': JobInput(dataset=f\"Adult_Train_from_Notebook:1\"),\n",
    "    'my_test_data': JobInput(dataset=f\"Adult_Test_from_Notebook:1\")\n",
    "}\n",
    "\n",
    "# Specify the training job\n",
    "train_job_inputs = {\n",
    "    'target_column_name': '${{inputs.target_column_name}}',\n",
    "    'training_data': '${{inputs.my_training_data}}',\n",
    "}\n",
    "train_job_outputs = {\n",
    "    'model_output': None\n",
    "}\n",
    "train_job = ComponentJob(\n",
    "    component=f\"MyTrainingComponent:1\",\n",
    "    inputs=train_job_inputs,\n",
    "    outputs=train_job_outputs\n",
    ")\n",
    "\n",
    "# The model registration job\n",
    "register_job_inputs = {\n",
    "    'model_input_path': '${{jobs.train-model-job.outputs.model_output}}',\n",
    "    'model_base_name': model_name,\n",
    "    'model_name_suffix': model_name_suffix\n",
    "}\n",
    "register_job_outputs = {\n",
    "    'model_info_output_path': None\n",
    "}\n",
    "register_job = ComponentJob(\n",
    "    component=f\"RegisterModel:{version_string}\",\n",
    "    inputs=register_job_inputs,\n",
    "    outputs=register_job_outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f721035",
   "metadata": {},
   "source": [
    "With our jobs specified, assemble them into a pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e6e8fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_registration_pipeline_job = PipelineJob(\n",
    "    experiment_name=f\"Register_Model_From_Notebook_01\",\n",
    "    description=\"Create and register a model from a notebook\",\n",
    "    jobs={\n",
    "        'train-model-job': train_job,\n",
    "        'register-model-job': register_job,\n",
    "    },\n",
    "    inputs=pipeline_inputs,\n",
    "    outputs=register_job_outputs,\n",
    "    compute=\"cpucluster\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9ba430",
   "metadata": {},
   "source": [
    "And now we can submit it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "defaa1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "compute is not a known attribute of class <class 'azure.ml._restclient.v2021_10_01.models._models_py3.PipelineJob'> and will be ignored\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PipelineJob({'display_name': 'salmon_tree_gx5mn4kc', 'type': 'pipeline', 'status': 'Preparing', 'log_files': None, 'parent_job_name': None, 'name': 'defa6a60-b1c1-48dd-be69-68d37685255d', 'description': 'Create and register a model from a notebook', 'tags': {'azureml.pipelineComponent': 'pipelinerun'}, 'properties': {'mlflow.source.git.repoURL': 'https://github.com/Azure/AutoML-vNext-Preview.git', 'mlflow.source.git.branch': 'riedgar-ms/full-notebook', 'mlflow.source.git.commit': 'e2977e646a4717828dd6fea22eada3c1bd672077', 'azureml.git.dirty': 'True', 'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'MFE', 'runType': 'HTTP', 'azureml.parameters': '{\"target_column_name\":\"income\"}', 'azureml.continue_on_step_failure': 'False', 'azureml.pipelineComponent': 'pipelinerun'}, 'id': '/subscriptions/589c7ae9-223e-45e3-a191-98433e0821a9/resourceGroups/amlisdkv2-rg-1638957740/providers/Microsoft.MachineLearningServices/workspaces/amlisdkv21638957740/jobs/defa6a60-b1c1-48dd-be69-68d37685255d', 'base_path': './', 'creation_context': <azure.ml._restclient.v2021_10_01.models._models_py3.SystemData object at 0x000001C99CA2B670>, 'serialize': <msrest.serialization.Serializer object at 0x000001C99C775370>, 'experiment_name': 'Register_Model_From_Notebook_01', 'compute': 'cpucluster', 'services': {'Tracking': <azure.ml._restclient.v2021_10_01.models._models_py3.JobService object at 0x000001C99CA2BD30>, 'Studio': <azure.ml._restclient.v2021_10_01.models._models_py3.JobService object at 0x000001C99CA2B400>}, 'inputs': {'target_column_name': 'income', 'my_training_data': {'dataset': 'Adult_Train_from_Notebook:1', 'mode': 'ro_mount'}, 'my_test_data': {'dataset': 'Adult_Test_from_Notebook:1', 'mode': 'ro_mount'}}, 'jobs': {'train-model-job': <azure.ml.entities._job.pipeline.component_job.ComponentJob object at 0x000001C99C775DF0>, 'register-model-job': <azure.ml.entities._job.pipeline.component_job.ComponentJob object at 0x000001C99C775A60>}, 'outputs': {'model_info_output_path': {'mode': 'rw_mount'}}, 'settings': {}})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.jobs.create_or_update(model_registration_pipeline_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa1feb1",
   "metadata": {},
   "source": [
    "# Creating the RAI Insights\n",
    "\n",
    "We have a registered model, and can now run a pipeline to create the RAI insights. First off, compute the name of the model we registered (this is not straightforward since the Register Model component is used in testing):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c2c1a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_model_id = f'{model_name}_{model_name_suffix}:1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c250e989",
   "metadata": {},
   "source": [
    "Now, we create the RAI pipeline itself. There are three 'component stages' in this pipeline:\n",
    "1. Fetch the model\n",
    "1. Construct an empty RAI dashboard\n",
    "1. Run the RAI tool components\n",
    "\n",
    "The job to fetch the registered model is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cd9f1b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This won't be necessary once models are types within the pipeline graph\n",
    "\n",
    "fetch_job_inputs = {\n",
    "    'model_id': expected_model_id\n",
    "}\n",
    "fetch_job_outputs = {\n",
    "    'model_info_output_path': None\n",
    "}\n",
    "fetch_job = ComponentJob(\n",
    "    component=f\"FetchRegisteredModel:{version_string}\",\n",
    "    inputs=fetch_job_inputs,\n",
    "    outputs=fetch_job_outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127a2a23",
   "metadata": {},
   "source": [
    "With this registered model (and our datasets), we can create an empty RAI dashboard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f5d8cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top level RAI Insights component\n",
    "\n",
    "# We will reuse the same pipeline_inputs object in the end\n",
    "create_rai_inputs = {\n",
    "    'title': 'Run built from a Notebook',\n",
    "    'task_type': 'classification',\n",
    "    'model_info_path': '${{jobs.fetch-model-job.outputs.model_info_output_path}}',\n",
    "    'train_dataset': '${{inputs.my_training_data}}',\n",
    "    'test_dataset': '${{inputs.my_test_data}}',\n",
    "    'target_column_name': '${{inputs.target_column_name}}',\n",
    "    'categorical_column_names': '[\"Race\", \"Sex\", \"Workclass\", \"Marital Status\", \"Country\", \"Occupation\"]',\n",
    "}\n",
    "create_rai_outputs = {\n",
    "    'rai_insights_dashboard': None # Could theoretically redirect the datastore here\n",
    "}\n",
    "create_rai_job = ComponentJob(\n",
    "    component=f\"RAIInsightsConstructor:{version_string}\",\n",
    "    inputs=create_rai_inputs,\n",
    "    outputs=create_rai_outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296d675f",
   "metadata": {},
   "source": [
    "Now, create an instance of each of our RAI tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "85e7e8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the explanation\n",
    "explain_inputs = {\n",
    "    'comment': 'Insert text here',\n",
    "    'rai_insights_dashboard': '${{jobs.create-rai-job.outputs.rai_insights_dashboard}}'\n",
    "}\n",
    "explain_outputs = {\n",
    "    'explanation': None\n",
    "}\n",
    "explain_job = ComponentJob(\n",
    "    component=f\"RAIInsightsExplanation:{version_string}\",\n",
    "    inputs=explain_inputs,\n",
    "    outputs=explain_outputs\n",
    ")\n",
    "\n",
    "# Setup causal\n",
    "causal_inputs = {\n",
    "    'rai_insights_dashboard': '${{jobs.create-rai-job.outputs.rai_insights_dashboard}}',\n",
    "    'treatment_features': '[\"Age\", \"Sex\"]',\n",
    "    'heterogeneity_features': '[\"Marital Status\"]'\n",
    "}\n",
    "causal_outputs = {\n",
    "    'causal': None\n",
    "}\n",
    "causal_job = ComponentJob(\n",
    "    component=f\"RAIInsightsCausal:{version_string}\",\n",
    "    inputs=causal_inputs,\n",
    "    outputs=causal_outputs\n",
    ")\n",
    "\n",
    "# Setup counterfactual\n",
    "counterfactual_inputs = {\n",
    "    'rai_insights_dashboard': '${{jobs.create-rai-job.outputs.rai_insights_dashboard}}',\n",
    "    'total_CFs': '10',\n",
    "    'desired_class': 'opposite'\n",
    "}\n",
    "counterfactual_outputs = {\n",
    "    'counterfactual': None\n",
    "}\n",
    "counterfactual_job = ComponentJob(\n",
    "    component=f\"RAIInsightsCounterfactual:{version_string}\",\n",
    "    inputs=counterfactual_inputs,\n",
    "    outputs=counterfactual_outputs\n",
    ")\n",
    "\n",
    "# Setup error analysis\n",
    "error_analysis_inputs = {\n",
    "    'rai_insights_dashboard': '${{jobs.create-rai-job.outputs.rai_insights_dashboard}}',\n",
    "    'filter_features': '[\"Race\", \"Sex\", \"Workclass\", \"Marital Status\", \"Country\", \"Occupation\"]'\n",
    "}\n",
    "error_analysis_outputs = {\n",
    "    'error_analysis': None\n",
    "}\n",
    "error_analysis_job = ComponentJob(\n",
    "    component=f\"RAIInsightsErrorAnalysis:{version_string}\",\n",
    "    inputs=error_analysis_inputs,\n",
    "    outputs=error_analysis_outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a00b52",
   "metadata": {},
   "source": [
    "Finally, we can put all of these into a pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5b2f0f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline to construct the RAI Insights\n",
    "insights_pipeline_job = PipelineJob(\n",
    "    experiment_name=f\"Compute_Insights_from_Notebook_{version_string}\",\n",
    "    description=\"Python submitted Adult insights using fetched model\",\n",
    "    jobs={\n",
    "        'fetch-model-job': fetch_job,\n",
    "        'create-rai-job': create_rai_job,\n",
    "        'causal-job': causal_job,\n",
    "        'counterfacual-job': counterfactual_job,\n",
    "        'error-analysis-job': error_analysis_job,\n",
    "        'explain-job': explain_job,\n",
    "    },\n",
    "    inputs=pipeline_inputs,\n",
    "    outputs=None,\n",
    "    compute=\"cpucluster\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451007e2",
   "metadata": {},
   "source": [
    "And submit it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d8df9d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "compute is not a known attribute of class <class 'azure.ml._restclient.v2021_10_01.models._models_py3.PipelineJob'> and will be ignored\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PipelineJob({'display_name': 'purple_kite_w6lx6pwb', 'type': 'pipeline', 'status': 'Preparing', 'log_files': None, 'parent_job_name': None, 'name': '86f9e1b8-d17e-49d9-8c2a-12b2a870c391', 'description': 'Python submitted Adult insights using fetched model', 'tags': {'azureml.pipelineComponent': 'pipelinerun'}, 'properties': {'mlflow.source.git.repoURL': 'https://github.com/Azure/AutoML-vNext-Preview.git', 'mlflow.source.git.branch': 'riedgar-ms/full-notebook', 'mlflow.source.git.commit': 'e2977e646a4717828dd6fea22eada3c1bd672077', 'azureml.git.dirty': 'True', 'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'MFE', 'runType': 'HTTP', 'azureml.parameters': '{\"target_column_name\":\"income\"}', 'azureml.continue_on_step_failure': 'False', 'azureml.pipelineComponent': 'pipelinerun'}, 'id': '/subscriptions/589c7ae9-223e-45e3-a191-98433e0821a9/resourceGroups/amlisdkv2-rg-1638957740/providers/Microsoft.MachineLearningServices/workspaces/amlisdkv21638957740/jobs/86f9e1b8-d17e-49d9-8c2a-12b2a870c391', 'base_path': './', 'creation_context': <azure.ml._restclient.v2021_10_01.models._models_py3.SystemData object at 0x000001C99C9E7AC0>, 'serialize': <msrest.serialization.Serializer object at 0x000001C99C9E7850>, 'experiment_name': 'Fetch_Model_for_Insights_1638957740', 'compute': 'cpucluster', 'services': {'Tracking': <azure.ml._restclient.v2021_10_01.models._models_py3.JobService object at 0x000001C99C76E7F0>, 'Studio': <azure.ml._restclient.v2021_10_01.models._models_py3.JobService object at 0x000001C99C76E7C0>}, 'inputs': {'target_column_name': 'income', 'my_training_data': {'dataset': 'Adult_Train_from_Notebook:1', 'mode': 'ro_mount'}, 'my_test_data': {'dataset': 'Adult_Test_from_Notebook:1', 'mode': 'ro_mount'}}, 'jobs': {'fetch-model-job': <azure.ml.entities._job.pipeline.component_job.ComponentJob object at 0x000001C99C9E76D0>, 'create-rai-job': <azure.ml.entities._job.pipeline.component_job.ComponentJob object at 0x000001C99C9E7280>, 'causal-job': <azure.ml.entities._job.pipeline.component_job.ComponentJob object at 0x000001C99C9E78B0>, 'counterfacual-job': <azure.ml.entities._job.pipeline.component_job.ComponentJob object at 0x000001C99C9E7550>, 'error-analysis-job': <azure.ml.entities._job.pipeline.component_job.ComponentJob object at 0x000001C99C9E7D00>, 'explain-job': <azure.ml.entities._job.pipeline.component_job.ComponentJob object at 0x000001C99C9E7A60>}, 'outputs': {}, 'settings': {}})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.jobs.create_or_update(insights_pipeline_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb05dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
