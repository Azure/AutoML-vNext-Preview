{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e8c50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Had to run from the shell:\n",
    "# ipython kernel install --name \"local-conda-env\" --user\n",
    "#import required libraries\n",
    "from azure.ml import MLClient\n",
    "from azure.ml.entities import ComponentJob, Code, PipelineJob, Dataset, InputDatasetEntry, CommandJob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3dab38",
   "metadata": {},
   "source": [
    "This notebook is for use with a workspace which has had the components and datasets uploaded by the build automation. This uses `epoch_seconds` as a version, so get these somewhere reusable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6413186",
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_version_suffix=\"1636365777\"\n",
    "component_dataset_version_suffix=\"1636389121\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576005c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter details of your AML workspace\n",
    "subscription_id = '589c7ae9-223e-45e3-a191-98433e0821a9'\n",
    "resource_group = f'amlisdkv2-rg-{workspace_version_suffix}'\n",
    "workspace = f'amlisdkv2{workspace_version_suffix}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cf2372",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a handle to the workspace\n",
    "ml_client = MLClient(subscription_id, resource_group, workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d7d83f",
   "metadata": {},
   "source": [
    "The next few cells aren't necessary, but were done before I learned how to connect to a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec554e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Dataset(\n",
    "    paths=['azureml:workspaceblobstore:LocalUpload/7686dd6cb00e860d4ab820252bb8d456/adult_train.parquet']\n",
    "    # name=\"Boston_Train_PQ\",\n",
    "    # version=\"1635933774\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b216d521",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sas = 'https://amlisdkvstoragea8b89ec4f.blob.core.windows.net/azureml-blobstore-860b3784-4c44-40fd-8e63-37c83ebd06f8/LocalUpload/7686dd6cb00e860d4ab820252bb8d456/adult_train.parquet?sp=r&st=2021-11-04T19:02:27Z&se=2021-11-05T03:02:27Z&spr=https&sv=2020-08-04&sr=b&sig=i004fOT9iYdZ1Gm%2FuwF5b7I8Z7S9tcL4y51Ysl5pAZQ%3D'\n",
    "\n",
    "get_data_cmd = 'bash fetch.bash \"'+data_sas+'\" adult_census.parquet ${{outputs.adultcensus}}'\n",
    "print(get_data_cmd)\n",
    "\n",
    "get_data_job = CommandJob(\n",
    "    command=get_data_cmd,\n",
    "    outputs={'adultcensus': None},\n",
    "    environment = 'AzureML-Minimal:18',\n",
    "    compute = 'cpucluster',\n",
    "    code=Code(local_path='fetch_script')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a1ff06",
   "metadata": {},
   "source": [
    "These are the global pipeline inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a124b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_inputs = { \n",
    "    'target_column_name':'income',\n",
    "    'my_training_data': InputDatasetEntry(dataset=f\"Adult_Train_PQ:{component_dataset_version_suffix}\"),\n",
    "    'my_test_data': InputDatasetEntry(dataset=f\"Adult_Test_PQ:{component_dataset_version_suffix}\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a018da",
   "metadata": {},
   "source": [
    "Create the training job, which creates a logistic regressor for the Adult Census dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db514ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_job_inputs = {\n",
    "    'target_column_name': '${{inputs.target_column_name}}',\n",
    "    'training_data': '${{inputs.my_training_data}}',\n",
    "}\n",
    "train_job_outputs = {\n",
    "    'model_output': None\n",
    "}\n",
    "\n",
    "train_job = ComponentJob(\n",
    "    component=f\"TrainLogisticRegressionForRAI:{component_dataset_version_suffix}\",\n",
    "    inputs = train_job_inputs,\n",
    "    outputs=train_job_outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4695f7",
   "metadata": {},
   "source": [
    "And a job to register the model and put out the JSON file which Model Analysis can read:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cde0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "register_job_inputs = {\n",
    "    'model_input_path': '${{jobs.train-model-job.outputs.model_output}}',\n",
    "    'model_base_name': 'notebook_registered_logreg',\n",
    "}\n",
    "register_job_outputs = {\n",
    "    'model_info_output_path': None\n",
    "}\n",
    "register_job = ComponentJob(\n",
    "    component=f\"RegisterModel:{component_dataset_version_suffix}\",\n",
    "    inputs = register_job_inputs,\n",
    "    outputs=register_job_outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b075a2d4",
   "metadata": {},
   "source": [
    "This is the top level Model Analysis job, which declares that we want to create an analysis. This will also take the data snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f4922b",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_ma_inputs = {\n",
    "    'title': 'Experimenting from a Notebook',\n",
    "    'task_type': 'classification',\n",
    "    'model_info_path': '${{jobs.register-model-job.outputs.model_info_output_path}}',\n",
    "    'train_dataset': '${{inputs.my_training_data}}',\n",
    "    'test_dataset': '${{inputs.my_test_data}}',\n",
    "    'target_column_name': '${{inputs.target_column_name}}',\n",
    "    'X_column_names': '[\"Age\", \"Workclass\", \"Education-Num\", \"Marital Status\", \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital Gain\", \"Capital Loss\", \"Hours per week\", \"Country\"]',\n",
    "    'datastore_name': 'workspaceblobstore',\n",
    "    'categorical_column_names': '[\"Race\", \"Sex\", \"Workclass\", \"Marital Status\", \"Country\", \"Occupation\"]',\n",
    "}\n",
    "create_ma_outputs = {\n",
    "    'model_analysis_info': None\n",
    "}\n",
    "create_ma_job = ComponentJob(\n",
    "    component=f\"AzureMLModelAnalysis:{component_dataset_version_suffix}\",\n",
    "    inputs = create_ma_inputs,\n",
    "    outputs=create_ma_outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973728c0",
   "metadata": {},
   "source": [
    "Create an explanation for the Model Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8400e070",
   "metadata": {},
   "outputs": [],
   "source": [
    "explain_inputs = {\n",
    "    'comment': 'Insert text here',\n",
    "    'model_analysis_info': '${{jobs.create-ma-job.outputs.model_analysis_info}}'\n",
    "}\n",
    "explain_job = ComponentJob(\n",
    "    component=f\"AzureMLModelAnalysisExplanation:{component_dataset_version_suffix}\",\n",
    "    inputs = explain_inputs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b9045a",
   "metadata": {},
   "source": [
    "Put all the jobs into a pipeline (note that several of them have already be referencing the keys in the `jobs` section)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6665d5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_job = PipelineJob(\n",
    "    description=\"Notebook submitted Adult\",\n",
    "    jobs = {\n",
    "        'train-model-job': train_job,\n",
    "        'register-model-job': register_job,\n",
    "        'create-ma-job': create_ma_job,\n",
    "        'explain-ma-job': explain_job,\n",
    "    },\n",
    "    inputs=pipeline_inputs,\n",
    "    outputs=train_job_outputs,\n",
    "    commpute=\"cpucluster\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4627b4",
   "metadata": {},
   "source": [
    "And the actual submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37f9550",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#submit the pipeline job\n",
    "returned_job = ml_client.jobs.create_or_update(pipeline_job)\n",
    "#get a URL for the status of the job\n",
    "returned_job.services[\"Studio\"].endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec37d40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f27be3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035e0b40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
